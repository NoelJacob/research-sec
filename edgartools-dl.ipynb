{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d214f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 137ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install edgartools ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6449b",
   "metadata": {},
   "source": [
    "## Download the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776d8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "\n",
    "import pandas as pd\n",
    "from edgar import Company, set_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873cec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_identity(\"Noel Jacob noeljacob91@gmail.com\")\n",
    "df = pd.read_csv(\"./mining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2dbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list: list[str] = df[\"Symbol\"].tolist()\n",
    "form_list = [\"10-K\", \"10-Q\", \"8-K\", \"6-K\", \"DEF 14A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_df = pd.DataFrame(columns=[\"Ticker\", \"Form\", \"Date\", \"Topics\"])\n",
    "for ticker in ticker_list:\n",
    "    try:\n",
    "        company = Company(ticker)\n",
    "        filings = company.get_filings(form=form_list)\n",
    "        for filing in filings:\n",
    "            form = filing.form\n",
    "            date = filing.filing_date\n",
    "\n",
    "            # filing_obj = filing.data_object()\n",
    "            # if filing_obj is not None and len(filing_obj.items) > 0:\n",
    "            #     topics = \",\".join(filing_obj.items)\n",
    "            #     print(f'so\"{topics}\"ok')\n",
    "            #     topic_df.loc[len(topic_df)] = [ticker, form, date, topics]\n",
    "\n",
    "            md = filing.markdown()\n",
    "            parent_dir = f\"./edgartools-data/{ticker}/{form}\"\n",
    "            makedirs(parent_dir, exist_ok=True)\n",
    "            with open(f\"{parent_dir}/{date}.md\", mode=\"w+\") as f:\n",
    "                f.write(md)\n",
    "    except Exception as e:\n",
    "        print(f\"Error {ticker}: {e}\")\n",
    "\n",
    "# topic_df.to_csv(\"./topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1af63",
   "metadata": {},
   "source": [
    "## Remove older than 2009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa89fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aaf9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_old_files(root_dir, cutoff_year=2009):\n",
    "    cutoff_date = datetime(cutoff_year, 1, 1)\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".md\"):\n",
    "                try:\n",
    "                    file_date = datetime.strptime(filename[:-3], \"%Y-%m-%d\")\n",
    "                    if file_date < cutoff_date:\n",
    "                        file_path = os.path.join(dirpath, filename)\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Deleted: {file_path}\")\n",
    "                except ValueError:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac237ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_old_files(\"./edgartools-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62434b20",
   "metadata": {},
   "source": [
    "## Filter using keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6a77719",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENERGY_STEMS = [\n",
    "    # Power & Energy basics\n",
    "    r\"electr\",  # electric, electrical, electricity\n",
    "    r\"(?<!voting )(?<!proxy )(?<!attorney )power\",\n",
    "    r\"energ\",\n",
    "    r\"watt\",  # watt, watts, wattage, kilowatt, megawatt, gigawatt\n",
    "    r\"volt\",  # volt, voltage, kilovolt\n",
    "    r\"(?<!ex)(?<!sw)(?<!cl)(?<!st)(?<!tr)(?<!d)amp(?!le|lif)\",  # avoid \"example\", \"swamp\", \"clamp\", \"stamp\", \"tramp\", \"damp\", \"ample\", \"amplify\" (unless you want amplify)\n",
    "    r\"joule\",\n",
    "    r\"btu\",\n",
    "    r\"therm\",\n",
    "    # Units\n",
    "    r\"kwh\",\n",
    "    r\"mwh\",\n",
    "    r\"gwh\",\n",
    "    r\"twh\",\n",
    "    # Mining specific\n",
    "    r\"(?<!re)hash\",  # avoid \"rehash\"\n",
    "    r\"\\basic\\b\",  # use word boundary instead of leading space for ASIC\n",
    "    # r\"mine\",  # miner, miners, mining\n",
    "    r\"s/s\"\n",
    "    r\"h/s\",\n",
    "    r\"/h\",\n",
    "    r\"/m\"\n",
    "    r\"/h\",\n",
    "    r\"/kh\",\n",
    "    r\"/mh\"\n",
    "    r\"/gh\",\n",
    "    r\"/th\",\n",
    "    # Generation & Sources\n",
    "    r\"generat\",  # generate, generation, generator\n",
    "    r\"solar\",\n",
    "    r\"wind\",\n",
    "    r\"hydro\",\n",
    "    r\"nuclear\",\n",
    "    r\"coal\",\n",
    "    r\"geotherm\",\n",
    "    r\"bio\",\n",
    "    r\"flare\",  # flared gas\n",
    "    r\"renewab\",  # renewable, renewables\n",
    "    r\"fossil\",\n",
    "    r\"fuel\",\n",
    "    # Infrastructure\n",
    "    r\"grid\",\n",
    "    r\"substation\",\n",
    "    r\"transformer\",\n",
    "    r\"transmiss\",  # transmission\n",
    "    r\"data[ \\-]?center\",  # consolidated pattern\n",
    "    r\"datacenter\",\n",
    "    r\"mining[ \\-]facilit\",  # facility, facilities\n",
    "    r\"interconnect\",\n",
    "    # Cooling & Efficiency\n",
    "    r\"cool(?![ \\-]?off)\",  # cooling, cooled, cooler\n",
    "    r\"hvac\",\n",
    "    r\"pue\",\n",
    "    r\"immersion\",\n",
    "    r\"heat\",\n",
    "    # Costs & Contracts\n",
    "    r\"utilit\",  # utility, utilities\n",
    "    r\"tariff\",\n",
    "    r\"\\bppa\\b\",  # word boundary instead of leading space\n",
    "    r\"curtail\",  # curtail, curtailment\n",
    "    r\"wholesale\",\n",
    "    # r\"rate\",\n",
    "    # Environmental\n",
    "    r\"\\bepa\\b\",  # word boundary\n",
    "    r\"carbon\",\n",
    "    r\"co2\",\n",
    "    r\"emission\",\n",
    "    r\"greenhouse\",\n",
    "    r\"ghg\",\n",
    "    r\"sustainab\",  # sustainable, sustainability\n",
    "    r\"esg\",\n",
    "    r\"footprint\",\n",
    "    r\"net[ \\-]?zero\",  # consolidated\n",
    "    r\"scope [123]\",  # consolidated\n",
    "    r\"(?<!super)(?<!un)(?<!pre)natural\",  # avoid \"supernatural\", \"unnatural\", \"preternatural\"\n",
    "    r\"\\bnatur\",  # word boundary\n",
    "    r\"environment\",\n",
    "    # Storage & Backup\n",
    "    r\"batter(?:y|ies)\",  # more specific\n",
    "    r\"(?<!cold )(?<!data )storage\",  # may want to exclude \"cold storage\" (financial term)\n",
    "    r\"\\bups\\b\",  # word boundary - avoid \"ups and downs\"\n",
    "    r\"diesel\",\n",
    "    r\"backup\",\n",
    "    # Regulatory\n",
    "    r\"\\bercot\\b\",\n",
    "    r\"\\bferc\\b\",\n",
    "    r\"\\bpjm\\b\",\n",
    "    r\"\\bnerc\\b\",\n",
    "    # r\"\\biso\\b\",  # careful - very common word\n",
    "    r\"\\brto\\b\",\n",
    "    # Consumption terms\n",
    "    r\"consum\",  # consume, consumption, consumer\n",
    "    r\"usage\",\n",
    "    r\"utiliz\",  # utilize, utilization\n",
    "    r\"efficien\",  # efficient, efficiency\n",
    "    r\"capacity\",\n",
    "    r\"load\",\n",
    "    r\"demand\",\n",
    "    r\"(?<!money )(?<!blood )(?<!food )(?<!labor )supply\",  # avoid non-energy supply\n",
    "    r\"procure\",  # procure, procurement\n",
    "    # noel\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee1c6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ENERGY_PATTERN = re.compile(\"|\".join(ENERGY_STEMS), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65a41720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept: 3231 files\n",
      "Would delete: 0 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def filter_energy_files(root_dir, dry_run=True):\n",
    "    \"\"\"Delete files without energy mentions. Set dry_run=False to actually delete.\"\"\"\n",
    "    deleted = []\n",
    "    kept = []\n",
    "\n",
    "    for filepath in Path(root_dir).rglob(\"*.md\"):\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        if ENERGY_PATTERN.search(content):\n",
    "            kept.append(str(filepath))\n",
    "        else:\n",
    "            print(f\"Deleted: {filepath}\")\n",
    "            deleted.append(str(filepath))\n",
    "            if not dry_run:\n",
    "                os.remove(filepath)\n",
    "\n",
    "    print(f\"Kept: {len(kept)} files\")\n",
    "    print(f\"{'Would delete' if dry_run else 'Deleted'}: {len(deleted)} files\")\n",
    "\n",
    "    return kept, deleted\n",
    "\n",
    "\n",
    "kept, to_delete = filter_energy_files(\"./edgartools-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924c476",
   "metadata": {},
   "source": [
    "## Find keywords in existing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "018c4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300/3231 files...\n",
      "Processed 600/3231 files...\n",
      "Processed 900/3231 files...\n",
      "Processed 1200/3231 files...\n",
      "Processed 1500/3231 files...\n",
      "Processed 1800/3231 files...\n",
      "Processed 2100/3231 files...\n",
      "Processed 2400/3231 files...\n",
      "Processed 2700/3231 files...\n",
      "Processed 3000/3231 files...\n",
      "Found 87819 matching lines\n",
      "Unique tickers: 32\n",
      "Unique terms matched:\n",
      "matched_terms\n",
      "power            8127\n",
      "coal             6694\n",
      "generat          5903\n",
      "electr           3761\n",
      "consum           3635\n",
      "demand           2750\n",
      "utiliz           2698\n",
      "environment      2482\n",
      "energ            2317\n",
      "hash             2193\n",
      "bio              2060\n",
      "natur            2045\n",
      "data center      1693\n",
      "supply           1423\n",
      "therm            1128\n",
      "capacity         1113\n",
      "efficien         1090\n",
      "amp               753\n",
      "storage           658\n",
      "electr, power     639\n",
      "Name: count, dtype: int64\n",
      "Saved to energy_matches_debug.csv\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_file(filepath: Path) -> list[dict]:\n",
    "    \"\"\"Process a single file and return matching records.\"\"\"\n",
    "    records = []\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        ticker = filepath.parts[1]\n",
    "        form = filepath.parts[2]\n",
    "        date = filepath.stem\n",
    "\n",
    "        for line_num, line in enumerate(lines, start=1):\n",
    "            matches = ENERGY_PATTERN.findall(line)\n",
    "            if matches:\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"ticker\": ticker,\n",
    "                        \"form\": form,\n",
    "                        \"date\": date,\n",
    "                        \"filepath\": str(filepath),\n",
    "                        \"line_num\": line_num,\n",
    "                        \"matched_terms\": \", \".join(set(m.lower() for m in matches)),\n",
    "                        \"line_text\": line.strip()[:500],\n",
    "                    }\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def extract_matching_sentences_parallel(root_dir, max_workers=8):\n",
    "    \"\"\"Extract sentences with energy matches using parallel processing.\"\"\"\n",
    "    files = list(Path(root_dir).rglob(\"*.md\"))\n",
    "    all_records = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_file, f): f for f in files}\n",
    "\n",
    "        for i, future in enumerate(as_completed(futures)):\n",
    "            records = future.result()\n",
    "            all_records.extend(records)\n",
    "            if (i + 1) % 300 == 0:\n",
    "                print(f\"Processed {i + 1}/{len(files)} files...\")\n",
    "\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "# Run parallel extraction\n",
    "matches_df = extract_matching_sentences_parallel(\"./edgartools-data\", max_workers=8)\n",
    "print(f\"Found {len(matches_df)} matching lines\")\n",
    "print(f\"Unique tickers: {matches_df['ticker'].nunique()}\")\n",
    "print(f\"Unique terms matched:\\n{matches_df['matched_terms'].value_counts().head(20)}\")\n",
    "\n",
    "matches_df.to_csv(\"./energy_matches_debug.csv\", index=False)\n",
    "print(\"Saved to energy_matches_debug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12d0832f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99797c07-ebe9-41d9-84d7-357b599b8edf",
       "rows": [
        [
         "GPUS",
         "15749"
        ],
        [
         "ARLP",
         "13165"
        ],
        [
         "RIOT",
         "5727"
        ],
        [
         "BMNR",
         "5626"
        ],
        [
         "CLSK",
         "5381"
        ],
        [
         "GREE",
         "5199"
        ],
        [
         "SLNH",
         "4704"
        ],
        [
         "MARA",
         "4318"
        ],
        [
         "WULF",
         "3709"
        ],
        [
         "CORZ",
         "3653"
        ],
        [
         "CIFR",
         "3261"
        ],
        [
         "MIGI",
         "2640"
        ],
        [
         "LMFA",
         "2577"
        ],
        [
         "APLD",
         "2161"
        ],
        [
         "ANY",
         "2126"
        ],
        [
         "OLB",
         "1916"
        ],
        [
         "ABTC",
         "1596"
        ],
        [
         "ARBK",
         "1222"
        ],
        [
         "IREN",
         "1116"
        ],
        [
         "HUT",
         "1041"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "ticker\n",
       "GPUS    15749\n",
       "ARLP    13165\n",
       "RIOT     5727\n",
       "BMNR     5626\n",
       "CLSK     5381\n",
       "GREE     5199\n",
       "SLNH     4704\n",
       "MARA     4318\n",
       "WULF     3709\n",
       "CORZ     3653\n",
       "CIFR     3261\n",
       "MIGI     2640\n",
       "LMFA     2577\n",
       "APLD     2161\n",
       "ANY      2126\n",
       "OLB      1916\n",
       "ABTC     1596\n",
       "ARBK     1222\n",
       "IREN     1116\n",
       "HUT      1041\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df[\"matched_terms\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and count individual terms\n",
    "matches_df[\"matched_terms\"] = matches_df[\"matched_terms\"].str.split(\", \")\n",
    "exploded_df = matches_df.explode(\"matched_terms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
