{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6755c888",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install google-genai pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"./edgartools-data\")\n",
    "OUTPUT_CSV = Path(\"./llm_energy_scores.csv\")\n",
    "SYSTEM_PROMPT_FILE = Path(\"./system_prompt.txt\")\n",
    "BATCH_REQUESTS_DIR = Path(\"./batch_requests\")\n",
    "BATCH_REQUESTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "BATCH_SIZE = 100  # Number of filings per batch job\n",
    "POLL_INTERVAL = 60  # Seconds between status checks\n",
    "\n",
    "# Gemini API setup\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec017ba9",
   "metadata": {},
   "source": [
    "## Load System Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SYSTEM_PROMPT_FILE, \"r\") as f:\n",
    "    SYSTEM_PROMPT = f.read()\n",
    "\n",
    "print(f\"Loaded system prompt ({len(SYSTEM_PROMPT)} chars)\")\n",
    "print(f\"First 200 chars: {SYSTEM_PROMPT[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227c7f3",
   "metadata": {},
   "source": [
    "## Discover All Filings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_filings(data_dir):\n",
    "    \"\"\"Discover all .md filings in the data directory.\"\"\"\n",
    "    filings = []\n",
    "\n",
    "    for filepath in data_dir.rglob(\"*.md\"):\n",
    "        parts = filepath.parts\n",
    "        ticker = parts[-3]\n",
    "        form = parts[-2]\n",
    "        date = filepath.stem\n",
    "\n",
    "        filings.append(\n",
    "            {\"ticker\": ticker, \"form\": form, \"date\": date, \"filepath\": str(filepath)}\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(filings)\n",
    "\n",
    "\n",
    "filings_df = discover_filings(DATA_DIR)\n",
    "print(f\"Discovered {len(filings_df)} filings\")\n",
    "print(f\"Tickers: {filings_df['ticker'].nunique()}\")\n",
    "print(f\"Forms: {filings_df['form'].value_counts().to_dict()}\")\n",
    "filings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b50df",
   "metadata": {},
   "source": [
    "## Load Previous Results (for Resumability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fcb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_results(output_csv):\n",
    "    \"\"\"Load already processed results to skip them.\"\"\"\n",
    "    if output_csv.exists():\n",
    "        df = pd.read_csv(output_csv)\n",
    "        print(f\"Loaded {len(df)} existing results\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No existing results found, starting fresh\")\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"ticker\",\n",
    "                \"form\",\n",
    "                \"date\",\n",
    "                \"filepath\",\n",
    "                \"chain_of_thought\",\n",
    "                \"estimated_mw\",\n",
    "                \"score\",\n",
    "                \"confidence\",\n",
    "                \"batch_job_name\",\n",
    "                \"timestamp\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "existing_results = load_existing_results(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9506ee0",
   "metadata": {},
   "source": [
    "## Filter Pending Filings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0edc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pending_filings(all_filings, existing_results):\n",
    "    \"\"\"Return filings that haven't been processed yet.\"\"\"\n",
    "    if len(existing_results) == 0:\n",
    "        return all_filings\n",
    "\n",
    "    # Create unique key for matching\n",
    "    all_filings[\"key\"] = (\n",
    "        all_filings[\"ticker\"] + \"_\" + all_filings[\"form\"] + \"_\" + all_filings[\"date\"]\n",
    "    )\n",
    "    existing_results[\"key\"] = (\n",
    "        existing_results[\"ticker\"]\n",
    "        + \"_\"\n",
    "        + existing_results[\"form\"]\n",
    "        + \"_\"\n",
    "        + existing_results[\"date\"]\n",
    "    )\n",
    "\n",
    "    processed_keys = set(existing_results[\"key\"])\n",
    "    pending = all_filings[~all_filings[\"key\"].isin(processed_keys)].copy()\n",
    "    pending = pending.drop(columns=[\"key\"])\n",
    "\n",
    "    return pending\n",
    "\n",
    "\n",
    "pending_filings = get_pending_filings(filings_df, existing_results)\n",
    "print(f\"Pending filings to process: {len(pending_filings)}\")\n",
    "print(f\"Already processed: {len(existing_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7ebf2",
   "metadata": {},
   "source": [
    "## Create Batch Request Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filing_text(filepath, max_chars=100000):\n",
    "    \"\"\"Read filing text, truncate if too long to manage costs.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Truncate if very long (to control token costs)\n",
    "        if len(content) > max_chars:\n",
    "            content = content[:max_chars] + \"\\n\\n[TRUNCATED FOR LENGTH]\"\n",
    "\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_batch_request_file(filings_batch, batch_idx, system_prompt):\n",
    "    \"\"\"Create a JSONL file for batch API submission.\"\"\"\n",
    "    jsonl_path = BATCH_REQUESTS_DIR / f\"batch_{batch_idx:04d}.jsonl\"\n",
    "\n",
    "    with open(jsonl_path, \"w\") as f:\n",
    "        for idx, row in filings_batch.iterrows():\n",
    "            filing_text = read_filing_text(row[\"filepath\"])\n",
    "            if filing_text is None:\n",
    "                continue\n",
    "\n",
    "            # Create unique key for this request\n",
    "            request_key = f\"{row['ticker']}_{row['form']}_{row['date']}\"\n",
    "\n",
    "            # Build the request\n",
    "            request = {\n",
    "                \"key\": request_key,\n",
    "                \"request\": {\n",
    "                    \"contents\": [\n",
    "                        {\n",
    "                            \"parts\": [\n",
    "                                {\n",
    "                                    \"text\": f\"{system_prompt}\\n\\n---\\n\\nFILING TO ANALYZE:\\n\\n{filing_text}\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"role\": \"user\",\n",
    "                        }\n",
    "                    ],\n",
    "                    \"generation_config\": {\n",
    "                        \"temperature\": 0.1,  # Low temperature for consistency\n",
    "                        \"response_mime_type\": \"application/json\",\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "\n",
    "            f.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "    return jsonl_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7928413",
   "metadata": {},
   "source": [
    "## Submit Batch Jobs & Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_batch_job(jsonl_path, batch_idx):\n",
    "    \"\"\"Upload JSONL and create a batch job.\"\"\"\n",
    "    try:\n",
    "        # Upload the JSONL file\n",
    "        print(\n",
    "            f\"Uploading batch {batch_idx} ({jsonl_path.stat().st_size / 1024 / 1024:.2f} MB)...\"\n",
    "        )\n",
    "        uploaded_file = client.files.upload(\n",
    "            file=str(jsonl_path),\n",
    "            config=types.UploadFileConfig(\n",
    "                display_name=f\"batch_{batch_idx:04d}\", mime_type=\"application/jsonl\"\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Uploaded file: {uploaded_file.name}\")\n",
    "\n",
    "        # Create the batch job\n",
    "        batch_job = client.batches.create(\n",
    "            model=f\"models/{MODEL_NAME}\",\n",
    "            src=uploaded_file.name,\n",
    "            config={\n",
    "                \"display_name\": f\"energy-scoring-batch-{batch_idx:04d}\",\n",
    "            },\n",
    "        )\n",
    "        print(f\"Created batch job: {batch_job.name}\")\n",
    "        return batch_job.name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error submitting batch {batch_idx}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def monitor_batch_job(job_name, poll_interval=60):\n",
    "    \"\"\"Monitor a batch job until completion.\"\"\"\n",
    "    completed_states = {\n",
    "        \"JOB_STATE_SUCCEEDED\",\n",
    "        \"JOB_STATE_FAILED\",\n",
    "        \"JOB_STATE_CANCELLED\",\n",
    "        \"JOB_STATE_EXPIRED\",\n",
    "    }\n",
    "\n",
    "    print(f\"Monitoring job: {job_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        batch_job = client.batches.get(name=job_name)\n",
    "        state = batch_job.state.name\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"[{elapsed / 60:.1f}m] State: {state}\")\n",
    "\n",
    "        if state in completed_states:\n",
    "            print(f\"Job finished with state: {state}\")\n",
    "            if state == \"JOB_STATE_FAILED\":\n",
    "                print(f\"Error: {batch_job.error}\")\n",
    "            return batch_job\n",
    "\n",
    "        time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab7c29",
   "metadata": {},
   "source": [
    "## Parse Results & Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_save_results(batch_job, filings_batch, batch_idx):\n",
    "    \"\"\"Download results, parse JSON, and append to CSV.\"\"\"\n",
    "    if batch_job.state.name != \"JOB_STATE_SUCCEEDED\":\n",
    "        print(f\"Batch {batch_idx} did not succeed, skipping\")\n",
    "        return\n",
    "\n",
    "    # Download result file\n",
    "    result_file_name = batch_job.dest.file_name\n",
    "    print(f\"Downloading results from: {result_file_name}\")\n",
    "    file_content_bytes = client.files.download(file=result_file_name)\n",
    "    file_content = file_content_bytes.decode(\"utf-8\")\n",
    "\n",
    "    # Parse JSONL results\n",
    "    results = []\n",
    "    for line in file_content.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            parsed = json.loads(line)\n",
    "\n",
    "            # Extract request key\n",
    "            if \"key\" not in parsed:\n",
    "                continue\n",
    "\n",
    "            request_key = parsed[\"key\"]\n",
    "            ticker, form, date = request_key.split(\"_\", 2)\n",
    "\n",
    "            # Get the corresponding filing info\n",
    "            filing_info = filings_batch[\n",
    "                (filings_batch[\"ticker\"] == ticker)\n",
    "                & (filings_batch[\"form\"] == form)\n",
    "                & (filings_batch[\"date\"] == date)\n",
    "            ]\n",
    "\n",
    "            if len(filing_info) == 0:\n",
    "                print(f\"Warning: Could not find filing for key {request_key}\")\n",
    "                continue\n",
    "\n",
    "            filepath = filing_info.iloc[0][\"filepath\"]\n",
    "\n",
    "            # Parse the LLM response\n",
    "            if \"response\" in parsed and parsed[\"response\"]:\n",
    "                response_text = parsed[\"response\"][\"candidates\"][0][\"content\"][\"parts\"][\n",
    "                    0\n",
    "                ][\"text\"]\n",
    "\n",
    "                # Parse JSON from response\n",
    "                try:\n",
    "                    llm_output = json.loads(response_text)\n",
    "\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"ticker\": ticker,\n",
    "                            \"form\": form,\n",
    "                            \"date\": date,\n",
    "                            \"filepath\": filepath,\n",
    "                            \"chain_of_thought\": llm_output.get(\"chain_of_thought\", \"\"),\n",
    "                            \"estimated_mw\": llm_output.get(\"estimated_mw\", -1),\n",
    "                            \"score\": llm_output.get(\"score\", -1),\n",
    "                            \"confidence\": llm_output.get(\"confidence\", 0),\n",
    "                            \"batch_job_name\": batch_job.name,\n",
    "                            \"timestamp\": pd.Timestamp.now(),\n",
    "                        }\n",
    "                    )\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing LLM JSON for {request_key}: {e}\")\n",
    "                    print(f\"Response text: {response_text[:200]}...\")\n",
    "\n",
    "            elif \"error\" in parsed:\n",
    "                print(f\"Error for {request_key}: {parsed['error']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {e}\")\n",
    "            print(f\"Line: {line[:200]}...\")\n",
    "\n",
    "    # Append to CSV\n",
    "    if len(results) > 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Append to existing CSV or create new\n",
    "        if OUTPUT_CSV.exists():\n",
    "            results_df.to_csv(OUTPUT_CSV, mode=\"a\", header=False, index=False)\n",
    "        else:\n",
    "            results_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "        print(f\"Saved {len(results)} results to {OUTPUT_CSV}\")\n",
    "        return results_df\n",
    "    else:\n",
    "        print(\"No valid results to save\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd238e2f",
   "metadata": {},
   "source": [
    "## Main Processing Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85803648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_batches(pending_filings, batch_size=100):\n",
    "    \"\"\"Main loop: create batches, submit, monitor, and save results.\"\"\"\n",
    "    total_batches = (len(pending_filings) + batch_size - 1) // batch_size\n",
    "    print(f\"Processing {len(pending_filings)} filings in {total_batches} batches\")\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"BATCH {batch_idx + 1}/{total_batches}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "        # Get batch slice\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(pending_filings))\n",
    "        filings_batch = pending_filings.iloc[start_idx:end_idx]\n",
    "\n",
    "        print(f\"Creating batch request file for {len(filings_batch)} filings...\")\n",
    "        jsonl_path = create_batch_request_file(filings_batch, batch_idx, SYSTEM_PROMPT)\n",
    "\n",
    "        print(\"Submitting batch job...\")\n",
    "        job_name = submit_batch_job(jsonl_path, batch_idx)\n",
    "\n",
    "        if job_name is None:\n",
    "            print(f\"Failed to submit batch {batch_idx}, skipping\")\n",
    "            continue\n",
    "\n",
    "        print(\"Monitoring batch job...\")\n",
    "        batch_job = monitor_batch_job(job_name, POLL_INTERVAL)\n",
    "\n",
    "        print(\"Parsing and saving results...\")\n",
    "        parse_and_save_results(batch_job, filings_batch, batch_idx)\n",
    "\n",
    "        print(f\"\\nBatch {batch_idx + 1} complete!\")\n",
    "\n",
    "        # Small delay between batches to be respectful\n",
    "        if batch_idx < total_batches - 1:\n",
    "            print(\"Waiting 10 seconds before next batch...\")\n",
    "            time.sleep(10)\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"ALL BATCHES COMPLETE!\")\n",
    "    print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8fb60",
   "metadata": {},
   "source": [
    "## Execute Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36006ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pending_filings) > 0:\n",
    "    process_all_batches(pending_filings, BATCH_SIZE)\n",
    "else:\n",
    "    print(\"No pending filings to process!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6215d22",
   "metadata": {},
   "source": [
    "## View Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final results\n",
    "if OUTPUT_CSV.exists():\n",
    "    final_results = pd.read_csv(OUTPUT_CSV)\n",
    "    print(f\"Total results: {len(final_results)}\")\n",
    "    print(\"\\nScore distribution:\")\n",
    "    print(final_results[\"score\"].describe())\n",
    "    print(\"\\nTickers with highest average scores:\")\n",
    "    print(\n",
    "        final_results.groupby(\"ticker\")[\"score\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "    )\n",
    "    final_results.head(10)\n",
    "else:\n",
    "    print(\"No results file found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e4983",
   "metadata": {},
   "source": [
    "## Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c993b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_CSV.exists():\n",
    "    results = pd.read_csv(OUTPUT_CSV)\n",
    "\n",
    "    # Filter out error cases\n",
    "    valid_results = results[results[\"score\"] >= 0]\n",
    "\n",
    "    print(f\"Total filings processed: {len(results)}\")\n",
    "    print(f\"Valid scores: {len(valid_results)}\")\n",
    "    print(f\"Error cases (score=-1): {len(results[results['score'] == -1])}\")\n",
    "    print(\"\\nConfidence distribution:\")\n",
    "    print(valid_results[\"confidence\"].describe())\n",
    "    print(\"\\nEstimated MW distribution:\")\n",
    "    print(valid_results[valid_results[\"estimated_mw\"] >= 0][\"estimated_mw\"].describe())\n",
    "\n",
    "    # Export summary by ticker\n",
    "    ticker_summary = (\n",
    "        valid_results.groupby(\"ticker\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"score\": [\"mean\", \"std\", \"count\"],\n",
    "                \"estimated_mw\": \"mean\",\n",
    "                \"confidence\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .round(2)\n",
    "    )\n",
    "    ticker_summary.columns = [\"_\".join(col) for col in ticker_summary.columns]\n",
    "    ticker_summary = ticker_summary.sort_values(\"score_mean\", ascending=False)\n",
    "\n",
    "    print(\"\\nTicker summary:\")\n",
    "    print(ticker_summary)\n",
    "\n",
    "    ticker_summary.to_csv(\"./ticker_energy_summary.csv\")\n",
    "    print(\"\\nSaved ticker summary to ticker_energy_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
